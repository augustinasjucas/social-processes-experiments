
== too old ---># python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 10 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.25 --max_epochs 250 --r_dim 10 --z_dim 5 --override_hid_dims --hid_dim 10 --log_file final_train_log-5.txt --my_use_softmax --my_ckpt "C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=027.ckpt"

To see pretty good info:
== too old ---> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 20 --z_dim 10 --override_hid_dims --hid_dim 20 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --my_ckpt "C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=178.ckpt"

With more metasamples trained, kl=0... (does not learn for z.)
== too old ---> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 30 --z_dim 20 --override_hid_dims --hid_dim 30 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --my_ckpt "C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=009.ckpt"

Something that works learning where to go (but bad data for learning q(z|C)).
== too old ---> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 12 --z_dim 8 --override_hid_dims --hid_dim 12 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --my_ckpt "C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=019.ckpt"


Failed experiment: (proper data for learning q(z|C))
== too old ---> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 10 --z_dim 7 --override_hid_dims --hid_dim 10 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --my_ckpt "C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=017.ckpt"

Maybe this can work:
== too old ---> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.25 --max_epochs 2500 --r_dim 32 --z_dim 32 --override_hid_dims --hid_dim 32 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1


=== Command for testing the "dominating" setting (3 observed, 1 future):
== idk what this was trained on -> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 6 --dropout 0.25 --max_epochs 2500 --r_dim 6 --z_dim 5 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 6  --my_context_size 4 --my_target_size 4 --my_observed_length 3 --my_future_length 1 --my_use_dominating --my_meta_sample_count_per_case 50  --my_repeat_count 2

Command for training the "random dual" setting: (3 observed, 1 future)
== idk what this was trained on -> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 6 --dropout 0.25 --max_epochs 2500 --r_dim 6 --z_dim 5 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 6  --my_context_size 4 --my_target_size 4 --my_observed_length 3 --my_future_length 1 --my_use_dominating --my_meta_sample_count_per_case 50  --my_repeat_count 2



TRAINED ON FFA DUAL (cant learn FFA dual, z 5-dimensional)
== buggy -> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 6 --z_dim 6 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 4 --my_target_size 4 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt "C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=065.ckpt"

Trained on FFA DUAL (z 1-dimensional, also does not work)
== buggy -> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 6 --z_dim 1 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 4 --my_target_size 4 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=039.ckpt --test


AFTER FIXING BUGS:
Working on FFA DUAL (z 1-dimensional)
== done -> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 8 --z_dim 1 --override_hid_dims --hid_dim 8 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 4 --my_target_size 4 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt "C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\mon-epoch=27-monitored_nll=-13.958.ckpt"

FFA DUAL (z 1-dimensional, 3 context, 4 timesteps)
== done -> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 8 --z_dim 1 --override_hid_dims --hid_dim 8 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 3 --my_target_size 3 --my_observed_length 1 --my_future_length 3 --my_use_ffa_dual --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=031-v0.ckpt --test
FFA DUAL (z 1-dimensional, 3 context, 4 timesteps, testing on dominating) === CLEARLY, DOES NOT LEARN
== done -> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 8 --z_dim 1 --override_hid_dims --hid_dim 8 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 3 --my_target_size 3 --my_observed_length 1 --my_future_length 3 --my_use_dominating --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=031-v0.ckpt --test


FFA DUAL (z 5-dimensional, 3 context, 4 timesteps) -- TOTAL POSTERIOR COLLAPSE!
== done -> python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 8 --z_dim 5 --override_hid_dims --hid_dim 8 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 3 --my_target_size 3 --my_observed_length 1 --my_future_length 3 --my_use_ffa_dual --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt "C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\mon-epoch=26-monitored_nll=141.463.ckpt"

FFA DUAL (z 5-dimensional, 10 context, 10 target, 1 observed, 3 future, 7 people, 200 meta samples per case). I.e., I give a shit-ton of data (WORKS)
python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 8 --z_dim 5 --override_hid_dims --hid_dim 8 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_ffa_dual --my_meta_sample_count_per_case 200  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=014.ckpt
Same tested on dominating:
python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 8 --z_dim 5 --override_hid_dims --hid_dim 8 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_dominating --my_meta_sample_count_per_case 200  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=014.ckpt


TRAINING WITH DOMINATING DATASET (LEARNS TO IDENTIFY THE DOMINATING PERSON, but not the clockwise/anticlockwise order!)
python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 8 --z_dim 5 --override_hid_dims --hid_dim 8 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_dominating --my_meta_sample_count_per_case 200  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt out-3\logs\checkpoints-synthetic\mon-epoch=29-monitored_nll=64.517.ckpt


Training with FFA DUAL RANDOM (and testing on it. Z - 5-dimensional LEARNS TO REMEMBER):
TO BE REDONE! python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 8 --z_dim 5 --override_hid_dims --hid_dim 8 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_ffa_dual_random --my_meta_sample_count_per_case 1  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 2000 --my_ckpt out-3\logs\checkpoints-synthetic\mon-epoch=12-monitored_nll=76.608.ckpt

training with FFA DUAL RANDOM, z 16-dimensional: (expecting this to learn to remember the context perfectly)
python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 16 --z_dim 16 --override_hid_dims --hid_dim 16 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_ffa_dual_random --my_meta_sample_count_per_case 1  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 2000 --my_ckpt out-3\logs\checkpoints-synthetic\mon-epoch=19-monitored_nll=109.736.ckpt

Training with FFA_FULL_RANDOM (q(z|C) collapses, learns to average shit out).
python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 6 --dropout 0.0 --max_epochs 2500 --r_dim 32 --z_dim 32 --override_hid_dims --hid_dim 32 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 6  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_ffa_full_random --my_meta_sample_count_per_case 1  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 2000 --my_ckpt out-3\logs\checkpoints-synthetic\mon-epoch=2-monitored_nll=154.783.ckpt



r"""

Training on dual_ffa
    - Learns dual ffa well
    - Works very bad with dominating. 
        a) 1-dimensional z: based on context decides "clockwise" or "anticlockwise" (or sometimes - interpolated version, probably).
         python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 6 --z_dim 1 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 4 --my_target_size 4 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=42-monitored_nll=-14.312.ckpt" --my_test_on_validation
        
        b) 5-dimensional z: Predicts some nonsense, kind of resembling just dual-ffa, but only kinda. Also very innacurate
        python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 8 --z_dim 5 --override_hid_dims --hid_dim 8 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_dominating --my_meta_sample_count_per_case 200  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_ckpt C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\last-epoch=014.ckpt

Training on dual_ffa_random
    - ATM, does not learn to remember the context, just predicts chess-like pattern
    - Does does not generalize for dominating, pretty much just predicts what it would predict for dual_ffa_random - i.e., chess pattern
    python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 16 --z_dim 16 --override_hid_dims --hid_dim 16 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_ffa_dual_random --my_meta_sample_count_per_case 1  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 2000 --my_ckpt out-3\logs\checkpoints-synthetic\mon-epoch=19-monitored_nll=109.736.ckpt
    
    - Does not posterior-collapse
        - Differnet z values result in different end results
        - Given some q(z | C), samples different samples result in very similar output predictions
        - Even then, it still typically predicts chess-like probability distribution, i.e., context seems to be useless
    

Training on full_ffa_random
    - Mayybe learns to remember the context in some cases
    - ??? Generalizes for dominating?
     
     
FULL FFA RANDOM, GOT REMEMBERING TO WORK (KINDA):
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 1 --outdir out-3 --skip_normalize_rot --data_dim 4 --dropout 0.0 --max_epochs 2500 --r_dim 32 --z_dim 32 --override_hid_dims --hid_dim 32 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 4  --my_context_size 5 --my_target_size 1 --my_observed_length 1 --my_future_length 1 --my_use_ffa_full_random --my_meta_sample_count_per_case 1  --my_repeat_count 1 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 4000 --nlayers 2 --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=29-monitored_nll=100.509.ckpt"

FULL FFA RANDOM, BIGGER VERSION, REMEMBERING SEEMS TO KINDA WORK:
 python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 4 --dropout 0.0 --max_epochs 2500 --r_dim 40 --z_dim 40 --override_hid_dims --hid_dim 40 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 4  --my_context_size 5 --my_target_size 1 --my_observed_length 1 --my_future_length 2 --my_use_dominating --my_meta_sample_count_per_case 1  --my_repeat_count 1 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 4000 --nlayers 3 --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=24-monitored_nll=122.775.ckpt" --my_how_many_z_samples_to_plot 4

Trying to get the remembering to work on longer datasets (with larger repeat count) SEEMS TO BE JUST DOING COUNTING:
 python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 4 --dropout 0.0 --max_epochs 2500 --r_dim 40 --z_dim 40 --override_hid_dims --hid_dim 40 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 4  --my_context_size 5 --my_target_size 1 --my_observed_length 1 --my_future_length 2 --my_use_ffa_full_random --my_meta_sample_count_per_case 1  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 4000 --nlayers 4 --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=25-monitored_nll=124.882.ckpt"

INDEPENDENT INFORMATION PROOF:
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 1 --outdir out-3 --skip_normalize_rot --data_dim 4 --dropout 0.0 --max_epochs 2500 --r_dim 32 --z_dim 32 --override_hid_dims --hid_dim 32 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 4  --my_context_size 5 --my_target_size 3 --my_observed_length 1 --my_future_length 1 --my_use_ffa_full_random --my_meta_sample_count_per_case 1  --my_repeat_count 1 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 4000 --nlayers 2 --my_context_independent_from_target --my_ckpt out-3\logs\checkpoints-synthetic\mon-epoch=4-monitored_nll=169.545.ckpt --my_test_on_validation

TRAINING DUAL FFA RANDOM ON THE SAME ARCHITECTURE AS fulll ramdom that learns; (does not really work!)
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 4 --dropout 0.0 --max_epochs 2500 --r_dim 40 --z_dim 40 --override_hid_dims --hid_dim 40 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 4  --my_context_size 5 --my_target_size 3 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual_random --my_meta_sample_count_per_case 1  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 2000 --nlayers 3 --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=21-monitored_nll=86.033.ckpt"

=========== DONE with these ^^^^ ================





USING CATEGORICAL CROSS-ENTROPY (NO SAMPLING FROM A CATEGORICAL DISTRIBUTION)
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 6 --z_dim 1 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 4 --my_target_size 4 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical  --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=30-monitored_nll=0.035.ckpt"


USING CATEGORICAL DISTRIBUTION:

dual:
z 1-dimensional: python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 6 --z_dim 1 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 4 --my_target_size 4 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical  --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=29-monitored_nll=0.038.ckpt"
z 5-dimensional: python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 8 --z_dim 5 --override_hid_dims --hid_dim 8 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_ffa_dual --my_meta_sample_count_per_case 200  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=33-monitored_nll=0.877.ckpt"

dual-random:
 python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 16 --z_dim 16 --override_hid_dims --hid_dim 16 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_ffa_dual_random --my_meta_sample_count_per_case 1  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 2000 --my_predict_categorical --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=17-monitored_nll=1.069.ckpt"

FFA full random:
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 6 --dropout 0.0 --max_epochs 2500 --r_dim 32 --z_dim 32 --override_hid_dims --hid_dim 32 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 6  --my_context_size 10 --my_target_size 10 --my_observed_length 1 --my_future_length 3 --my_use_ffa_full_random --my_meta_sample_count_per_case 1  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 2000 --my_predict_categorical --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=6-monitored_nll=1.797.ckpt"

Categorical small full random:
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 4 --dropout 0.0 --max_epochs 2500 --r_dim 40 --z_dim 40 --override_hid_dims --hid_dim 40 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 4  --my_context_size 5 --my_target_size 3 --my_observed_length 1 --my_future_length 2 --my_use_dominating --my_meta_sample_count_per_case 1  --my_repeat_count 1 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 4000 --nlayers 3 --my_predict_categorical --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=5-monitored_nll=1.386.ckpt" --my_how_many_z_samples_to_plot 4


======== (controlled setting: 1-dimensional z) ========
Trained on DUAL dataset:
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 6 --z_dim 1 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 4 --my_target_size 4 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical  --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=29-monitored_nll=0.038.ckpt"

Trained on DUAL-RANDOM dataset:
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 6 --z_dim 1 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 4 --my_target_size 4 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual_random --my_meta_sample_count_per_case 100  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=191-monitored_nll=0.900.ckpt" 

Trained on FULL-RANDOM dataset:
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 6 --z_dim 1 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 4 --my_target_size 4 --my_observed_length 1 --my_future_length 2 --my_use_ffa_full_random --my_meta_sample_count_per_case 1 --my_how_many_random_permutations 2000  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=8-monitored_nll=1.984.ckpt"

Displays all of those:
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 7 --dropout 0.0 --max_epochs 2500 --r_dim 6 --z_dim 1 --override_hid_dims --hid_dim 6 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 7  --my_context_size 4 --my_target_size 4 --my_observed_length 1 --my_future_length 2 --my_use_ffa_full_random --my_meta_sample_count_per_case 1 --my_how_many_random_permutations 2000  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --my_analyse_datasets --my_ffa_dual_model  "out-3\logs\checkpoints-synthetic\mon-epoch=29-monitored_nll=0.038.ckpt" --my_ffa_dual_random_model "out-3\logs\checkpoints-synthetic\mon-epoch=191-monitored_nll=0.900.ckpt" --my_ffa_full_random_model "out-3\logs\checkpoints-synthetic\mon-epoch=8-monitored_nll=1.984.ckpt" --my_plot_posteriors


remembering with lower z (:
python -m run.ordering.run_ordering_experiment --gpus 1 --future_len 1 --outdir out-3 --skip_normalize_rot --data_dim 4 --dropout 0.0 --max_epochs 2500 --r_dim 32 --z_dim 16 --override_hid_dims --hid_dim 32 --log_file final_train_log-5.txt --my_use_softmax --fix_variance --nz_samples 1 --my_people_count 4  --my_context_size 5 --my_target_size 1 --my_observed_length 1 --my_future_length 1 --my_use_ffa_full_random --my_meta_sample_count_per_case 1  --my_repeat_count 1 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 4000 --nlayers 4 --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=42-monitored_nll=93.964.ckpt"

remembering with lower z:
    just same with "categorical" changed (context remembering works, but does not use X): python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 1 --outdir out-3 --skip_normalize_rot --data_dim 4 --dropout 0.0 --max_epochs 2500 --r_dim 32 --z_dim 32 --override_hid_dims --hid_dim 32 --log_file final_train_log-5.txt --my_predict_categorical --fix_variance --nz_samples 1 --my_people_count 4  --my_context_size 5 --my_target_size 1 --my_observed_length 1 --my_future_length 1 --my_use_ffa_full_random --my_meta_sample_count_per_case 1  --my_repeat_count 1 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 4000 --nlayers 2 --my_ckpt out-3\logs\checkpoints-synthetic\mon-epoch=58-monitored_nll=7.509.ckpt
    with higher nlayers=4: python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 1 --outdir out-3 --skip_normalize_rot --data_dim 4 --dropout 0.0 --max_epochs 2500 --r_dim 32 --z_dim 32 --override_hid_dims --hid_dim 32 --log_file final_train_log-5.txt --my_predict_categorical --fix_variance --nz_samples 1 --my_people_count 4  --my_context_size 5 --my_target_size 1 --my_observed_length 1 --my_future_length 1 --my_use_ffa_full_random --my_meta_sample_count_per_case 1  --my_repeat_count 1 --my_merge_observed_with_future --my_merge_context --my_how_many_random_permutations 4000 --nlayers 4 --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=20-monitored_nll=7.533.ckpt"
 
 



====== MOST REALISTIC SETTING: 5 people, 8 context interactions, 3 target interactions, 
1-dimensional z:
DUAL:        python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 64 --z_dim 1 --override_hid_dims --hid_dim 64 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 5  --my_context_size 8 --my_target_size 3 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual --my_meta_sample_count_per_case 100 --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --nlayers 5 --my_ckpt  "out-3\logs\checkpoints-synthetic\mon-epoch=12-monitored_nll=0.006.ckpt"
DUAL-RANDOM: python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 64 --z_dim 1 --override_hid_dims --hid_dim 64 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 5  --my_context_size 8 --my_target_size 3 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual_random --my_meta_sample_count_per_case 100 --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --nlayers 5 --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=62-monitored_nll=38.022.ckpt"
FULL-RANDOM: python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 64 --z_dim 1 --override_hid_dims --hid_dim 64 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 5  --my_context_size 8 --my_target_size 3 --my_observed_length 1 --my_future_length 2 --my_use_ffa_full_random  --my_meta_sample_count_per_case 1 --my_how_many_random_permutations 2000 --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --nlayers 5 --my_ckpt  "out-3\logs\checkpoints-synthetic\mon-epoch=22-monitored_nll=70.348.ckpt"
 displays all:
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 64 --z_dim 64 --override_hid_dims --hid_dim 64 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 5  --my_context_size 8 --my_target_size 3 --my_observed_length 1 --my_future_length 2 --my_use_ffa_full_random --my_meta_sample_count_per_case 1 --my_how_many_random_permutations 2000  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --my_analyse_datasets --my_ffa_dual_model "out-3\logs\checkpoints-synthetic\mon-epoch=12-monitored_nll=0.006.ckpt" --my_ffa_dual_random_model "out-3\logs\checkpoints-synthetic\mon-epoch=62-monitored_nll=38.022.ckpt" --my_ffa_full_random_model "out-3\logs\checkpoints-synthetic\mon-epoch=22-monitored_nll=70.348.ckpt" --my_plot_posteriors

 
multidimensional z:
DUAL:        python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 64 --z_dim 64 --override_hid_dims --hid_dim 64 --log_file final_train_log-6.txt --fix_variance --nz_samples 1 --my_people_count 5  --my_context_size 8 --my_target_size 3 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual --my_meta_sample_count_per_case 100 --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --nlayers 5 --my_ckpt "out-3\logs\checkpoints-synthetic\mon-epoch=28-monitored_nll=0.001.ckpt"
DUAL-RANDOM: python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 64 --z_dim 64 --override_hid_dims --hid_dim 64 --log_file final_train_log-7.txt --fix_variance --nz_samples 1 --my_people_count 5  --my_context_size 8 --my_target_size 3 --my_observed_length 1 --my_future_length 2 --my_use_ffa_dual_random --my_meta_sample_count_per_case 100 --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --nlayers 5 --my_ckpt C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\mon-epoch=103-monitored_nll=38.794-v0.ckpt
FULL-RANDOM: python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 64 --z_dim 64 --override_hid_dims --hid_dim 64 --log_file final_train_log-8.txt --fix_variance --nz_samples 1 --my_people_count 5  --my_context_size 8 --my_target_size 3 --my_observed_length 1 --my_future_length 2 --my_use_ffa_full_random  --my_meta_sample_count_per_case 1 --my_how_many_random_permutations 2000 --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --nlayers 5 --my_ckpt  "out-3\logs\checkpoints-synthetic\mon-epoch=76-monitored_nll=69.785.ckpt"
 displays all:
python -m run.ordering.test_ordering_experiment --gpus 1 --future_len 2 --outdir out-3 --skip_normalize_rot --data_dim 5 --dropout 0.0 --max_epochs 2500 --r_dim 64 --z_dim 64 --override_hid_dims --hid_dim 64 --log_file final_train_log-5.txt --fix_variance --nz_samples 1 --my_people_count 5  --my_context_size 8 --my_target_size 3 --my_observed_length 1 --my_future_length 2 --my_use_ffa_full_random --my_meta_sample_count_per_case 1 --my_how_many_random_permutations 2000  --my_repeat_count 2 --my_merge_observed_with_future --my_merge_context --my_predict_categorical --my_analyse_datasets --my_ffa_dual_model "out-3\logs\checkpoints-synthetic\mon-epoch=28-monitored_nll=0.001.ckpt" --my_ffa_dual_random_model "C:\Users\augus\Desktop\social-processes-experiments\out-3\logs\checkpoints-synthetic\mon-epoch=103-monitored_nll=38.794-v0.ckpt" --my_ffa_full_random_model "out-3\logs\checkpoints-synthetic\mon-epoch=76-monitored_nll=69.785.ckpt" --my_plot_posteriors


 installing pip:
 pip install numpy==1.26.4
"""